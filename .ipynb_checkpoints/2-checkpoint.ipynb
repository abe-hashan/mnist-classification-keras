{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.datasets import mnist\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-shuffled MNIST data into train and test sets\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "#Exploring shape of test set\n",
    "\n",
    "print(X_train.shape) \n",
    "print(y_train.shape) \n",
    "print(X_test.shape) \n",
    "print(y_test.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1cd9c01b148>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting the first image of training set\n",
    "\n",
    "plt.imshow(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# reshaping the dimensions of images upto 4 as required by keras\n",
    "\n",
    "X_train = np.expand_dims(X_train, -1)\n",
    "X_test = np.expand_dims(X_test, -1)\n",
    "\n",
    "# See how it is rehaped\n",
    "\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# Making all the values as float to preserve decimal points after a division\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# Normalizing the values to be in the range of 0 - 1\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print(X_train.shape) \n",
    "print(X_test.shape) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding noise of 0.25\n",
    "\n",
    "noise_factor = 0.25\n",
    "X_train_noisy_25 = X_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_train.shape)\n",
    "X_test_noisy_25 = X_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_test.shape)\n",
    "X_train_noisy_25 = np.clip(X_train_noisy_25, 0. , 1.)\n",
    "X_test_noisy_25 = np.clip(X_test_noisy_25, 0. , 1.)\n",
    "\n",
    "# Adding noise of 0.40\n",
    "\n",
    "noise_factor = 0.40\n",
    "X_train_noisy_40 = X_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_train.shape)\n",
    "X_test_noisy_40 = X_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_test.shape)\n",
    "X_train_noisy_40 = np.clip(X_train_noisy_40, 0. , 1.)\n",
    "X_test_noisy_40 = np.clip(X_test_noisy_40, 0. , 1.)\n",
    "\n",
    "# Adding noise of 0.60\n",
    "\n",
    "noise_factor = 0.60\n",
    "X_train_noisy_60 = X_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_train.shape)\n",
    "X_test_noisy_60 = X_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_test.shape)\n",
    "X_train_noisy_60 = np.clip(X_train_noisy_60, 0. , 1.)\n",
    "X_test_noisy_60 = np.clip(X_test_noisy_60, 0. , 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 ... 5 6 8]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)\n",
    "\n",
    "# one hot encoding train and test classes \n",
    "class_count = 10\n",
    "y_train = keras.utils.to_categorical(y_train, class_count)\n",
    "y_test = keras.utils.to_categorical(y_test, class_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_25 = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(class_count, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_40 = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(class_count, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_60 = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(class_count, activation=\"softmax\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "422/422 [==============================] - 50s 119ms/step - loss: 0.4658 - accuracy: 0.8602 - val_loss: 0.1109 - val_accuracy: 0.9693\n",
      "Epoch 2/15\n",
      "422/422 [==============================] - 48s 113ms/step - loss: 0.1517 - accuracy: 0.9539 - val_loss: 0.0800 - val_accuracy: 0.9787\n",
      "Epoch 3/15\n",
      "422/422 [==============================] - 52s 123ms/step - loss: 0.1145 - accuracy: 0.9650 - val_loss: 0.0670 - val_accuracy: 0.9823\n",
      "Epoch 4/15\n",
      "422/422 [==============================] - 47s 111ms/step - loss: 0.0962 - accuracy: 0.9704 - val_loss: 0.0599 - val_accuracy: 0.9830\n",
      "Epoch 5/15\n",
      "422/422 [==============================] - 46s 109ms/step - loss: 0.0881 - accuracy: 0.9729 - val_loss: 0.0535 - val_accuracy: 0.9852\n",
      "Epoch 6/15\n",
      "422/422 [==============================] - 46s 109ms/step - loss: 0.0800 - accuracy: 0.9750 - val_loss: 0.0521 - val_accuracy: 0.9853\n",
      "Epoch 7/15\n",
      "422/422 [==============================] - 48s 114ms/step - loss: 0.0729 - accuracy: 0.9765 - val_loss: 0.0476 - val_accuracy: 0.9867\n",
      "Epoch 8/15\n",
      "422/422 [==============================] - 48s 113ms/step - loss: 0.0683 - accuracy: 0.9783 - val_loss: 0.0475 - val_accuracy: 0.9872\n",
      "Epoch 9/15\n",
      "422/422 [==============================] - 47s 111ms/step - loss: 0.0652 - accuracy: 0.9797 - val_loss: 0.0460 - val_accuracy: 0.9860\n",
      "Epoch 10/15\n",
      "422/422 [==============================] - 50s 118ms/step - loss: 0.0620 - accuracy: 0.9804 - val_loss: 0.0466 - val_accuracy: 0.9850\n",
      "Epoch 11/15\n",
      "422/422 [==============================] - 49s 117ms/step - loss: 0.0592 - accuracy: 0.9810 - val_loss: 0.0434 - val_accuracy: 0.9883\n",
      "Epoch 12/15\n",
      "422/422 [==============================] - 46s 108ms/step - loss: 0.0576 - accuracy: 0.9820 - val_loss: 0.0453 - val_accuracy: 0.9872\n",
      "Epoch 13/15\n",
      "422/422 [==============================] - 51s 121ms/step - loss: 0.0540 - accuracy: 0.9828 - val_loss: 0.0424 - val_accuracy: 0.9883\n",
      "Epoch 14/15\n",
      "422/422 [==============================] - 53s 127ms/step - loss: 0.0522 - accuracy: 0.9833 - val_loss: 0.0413 - val_accuracy: 0.9888\n",
      "Epoch 15/15\n",
      "422/422 [==============================] - 48s 114ms/step - loss: 0.0504 - accuracy: 0.9841 - val_loss: 0.0434 - val_accuracy: 0.9887\n",
      "Epoch 1/15\n",
      "422/422 [==============================] - 53s 125ms/step - loss: 0.5798 - accuracy: 0.8198 - val_loss: 0.1690 - val_accuracy: 0.9532\n",
      "Epoch 2/15\n",
      "422/422 [==============================] - 48s 113ms/step - loss: 0.2133 - accuracy: 0.9338 - val_loss: 0.1176 - val_accuracy: 0.9662\n",
      "Epoch 3/15\n",
      "422/422 [==============================] - 43s 102ms/step - loss: 0.1664 - accuracy: 0.9480 - val_loss: 0.1060 - val_accuracy: 0.9703\n",
      "Epoch 4/15\n",
      "422/422 [==============================] - 48s 114ms/step - loss: 0.1443 - accuracy: 0.9549 - val_loss: 0.0987 - val_accuracy: 0.9712\n",
      "Epoch 5/15\n",
      "422/422 [==============================] - 53s 125ms/step - loss: 0.1313 - accuracy: 0.9589 - val_loss: 0.0866 - val_accuracy: 0.9772\n",
      "Epoch 6/15\n",
      "422/422 [==============================] - 49s 116ms/step - loss: 0.1222 - accuracy: 0.9614 - val_loss: 0.0859 - val_accuracy: 0.9767\n",
      "Epoch 7/15\n",
      "422/422 [==============================] - 44s 104ms/step - loss: 0.1106 - accuracy: 0.9654 - val_loss: 0.0806 - val_accuracy: 0.9765\n",
      "Epoch 8/15\n",
      "422/422 [==============================] - 51s 120ms/step - loss: 0.1083 - accuracy: 0.9652 - val_loss: 0.0742 - val_accuracy: 0.9798\n",
      "Epoch 9/15\n",
      "422/422 [==============================] - 49s 116ms/step - loss: 0.1021 - accuracy: 0.9671 - val_loss: 0.0731 - val_accuracy: 0.9793\n",
      "Epoch 10/15\n",
      "422/422 [==============================] - 46s 108ms/step - loss: 0.0964 - accuracy: 0.9698 - val_loss: 0.0720 - val_accuracy: 0.9797\n",
      "Epoch 11/15\n",
      "422/422 [==============================] - 45s 108ms/step - loss: 0.0957 - accuracy: 0.9699 - val_loss: 0.0670 - val_accuracy: 0.9815\n",
      "Epoch 12/15\n",
      "422/422 [==============================] - 49s 115ms/step - loss: 0.0914 - accuracy: 0.9705 - val_loss: 0.0687 - val_accuracy: 0.9803\n",
      "Epoch 13/15\n",
      "422/422 [==============================] - 48s 113ms/step - loss: 0.0872 - accuracy: 0.9716 - val_loss: 0.0679 - val_accuracy: 0.9820\n",
      "Epoch 14/15\n",
      "422/422 [==============================] - 48s 115ms/step - loss: 0.0889 - accuracy: 0.9706 - val_loss: 0.0648 - val_accuracy: 0.9818\n",
      "Epoch 15/15\n",
      "422/422 [==============================] - 44s 105ms/step - loss: 0.0835 - accuracy: 0.9729 - val_loss: 0.0676 - val_accuracy: 0.9817\n",
      "Epoch 1/15\n",
      "422/422 [==============================] - 46s 108ms/step - loss: 0.7726 - accuracy: 0.7526 - val_loss: 0.2836 - val_accuracy: 0.9140\n",
      "Epoch 2/15\n",
      "422/422 [==============================] - 46s 110ms/step - loss: 0.3684 - accuracy: 0.8834 - val_loss: 0.2297 - val_accuracy: 0.9313\n",
      "Epoch 3/15\n",
      "422/422 [==============================] - 44s 105ms/step - loss: 0.3109 - accuracy: 0.9006 - val_loss: 0.2011 - val_accuracy: 0.9402\n",
      "Epoch 4/15\n",
      "422/422 [==============================] - 40s 94ms/step - loss: 0.2873 - accuracy: 0.9087 - val_loss: 0.1827 - val_accuracy: 0.9478\n",
      "Epoch 5/15\n",
      "422/422 [==============================] - 38s 90ms/step - loss: 0.2705 - accuracy: 0.9132 - val_loss: 0.1779 - val_accuracy: 0.9458\n",
      "Epoch 6/15\n",
      "422/422 [==============================] - 42s 100ms/step - loss: 0.2571 - accuracy: 0.9175 - val_loss: 0.1699 - val_accuracy: 0.9507\n",
      "Epoch 7/15\n",
      "422/422 [==============================] - 38s 89ms/step - loss: 0.2442 - accuracy: 0.9198 - val_loss: 0.1590 - val_accuracy: 0.9515\n",
      "Epoch 8/15\n",
      "422/422 [==============================] - 37s 88ms/step - loss: 0.2376 - accuracy: 0.9226 - val_loss: 0.1599 - val_accuracy: 0.9530\n",
      "Epoch 9/15\n",
      "422/422 [==============================] - 35s 83ms/step - loss: 0.2337 - accuracy: 0.9246 - val_loss: 0.1576 - val_accuracy: 0.9538\n",
      "Epoch 10/15\n",
      "422/422 [==============================] - 35s 83ms/step - loss: 0.2274 - accuracy: 0.9262 - val_loss: 0.1517 - val_accuracy: 0.9537\n",
      "Epoch 11/15\n",
      "422/422 [==============================] - 35s 84ms/step - loss: 0.2212 - accuracy: 0.9281 - val_loss: 0.1498 - val_accuracy: 0.9535\n",
      "Epoch 12/15\n",
      "422/422 [==============================] - 37s 89ms/step - loss: 0.2178 - accuracy: 0.9295 - val_loss: 0.1465 - val_accuracy: 0.9543\n",
      "Epoch 13/15\n",
      "422/422 [==============================] - 36s 84ms/step - loss: 0.2144 - accuracy: 0.9291 - val_loss: 0.1477 - val_accuracy: 0.9532\n",
      "Epoch 14/15\n",
      "422/422 [==============================] - 35s 83ms/step - loss: 0.2130 - accuracy: 0.9315 - val_loss: 0.1474 - val_accuracy: 0.9560\n",
      "Epoch 15/15\n",
      "422/422 [==============================] - 35s 83ms/step - loss: 0.2103 - accuracy: 0.9314 - val_loss: 0.1456 - val_accuracy: 0.9553\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cd8498d948>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 15\n",
    "\n",
    "model_25.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model_25.fit(X_train_noisy_25, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "\n",
    "model_40.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model_40.fit(X_train_noisy_40, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "\n",
    "model_60.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model_60.fit(X_train_noisy_60, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss noise 25: 0.037031494081020355\n",
      "Test accuracy noise 25: 0.9868999719619751\n",
      "Test loss noise 40: 0.06714973598718643\n",
      "Test accuracy noise 40: 0.9779999852180481\n",
      "Test loss noise 60: 0.1590907722711563\n",
      "Test accuracy noise 60: 0.9506999850273132\n"
     ]
    }
   ],
   "source": [
    "score = model_25.evaluate(X_test_noisy_25, y_test, verbose=0)\n",
    "print(\"Test loss noise 25:\", score[0])\n",
    "print(\"Test accuracy noise 25:\", score[1])\n",
    "\n",
    "score = model_40.evaluate(X_test_noisy_40, y_test, verbose=0)\n",
    "print(\"Test loss noise 40:\", score[0])\n",
    "print(\"Test accuracy noise 40:\", score[1])\n",
    "\n",
    "score = model_60.evaluate(X_test_noisy_60, y_test, verbose=0)\n",
    "print(\"Test loss noise 60:\", score[0])\n",
    "print(\"Test accuracy noise 60:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
